Run configurations: model=allenai/unifiedqa-v2-t5-large-1251000 train=./data/unifiedQA/train_direct_1000.json eval=./data/unifiedQA/test.json train_batch=4 eval_batch=8 epochs=30
Dataset	Epoch	Precision	Recall	F1	Accuracy
train	-1	0.7753479125248509	0.78	0.7776669990029911	0.777
eval	-1	0.9411764705882353	0.8571428571428571	0.897196261682243	0.89
train	0	0.8949343339587242	0.954	0.9235237173281704	0.921
eval	0	0.9279279279279279	0.9196428571428571	0.9237668161434976	0.915
train	1	0.9559386973180076	0.998	0.9765166340508805	0.976
eval	1	0.8780487804878049	0.9642857142857143	0.9191489361702128	0.905
train	2	0.9822834645669292	0.998	0.9900793650793651	0.989
eval	2	0.9210526315789473	0.9375	0.9292035398230089	0.92
train	3	0.9979838709677419	0.99	0.9939759036144579	0.994
eval	3	0.9252336448598131	0.8839285714285714	0.9041095890410958	0.895
train	4	0.9861932938856016	1.0	0.9930486593843098	0.993
eval	4	0.9285714285714286	0.9285714285714286	0.9285714285714286	0.92
train	5	0.9920318725099602	0.996	0.9940119760479043	0.994
eval	5	0.9285714285714286	0.9285714285714286	0.9285714285714286	0.92
train	6	0.998003992015968	1.0	0.9990009990009989	0.999
eval	6	0.926605504587156	0.9017857142857143	0.9140271493212669	0.905
train	7	0.998	0.998	0.998	0.998
eval	7	0.926605504587156	0.9017857142857143	0.9140271493212669	0.905
train	8	0.998003992015968	1.0	0.9990009990009989	0.999
eval	8	0.9043478260869565	0.9285714285714286	0.9162995594713658	0.905
train	9	1.0	0.998	0.998998998998999	0.999
eval	9	0.9090909090909091	0.8928571428571429	0.9009009009009009	0.89
train	10	1.0	0.998	0.998998998998999	0.999
eval	10	0.9174311926605505	0.8928571428571429	0.9049773755656108	0.895
train	11	0.9936974789915967	0.946	0.9692622950819673	0.97
eval	11	0.9175257731958762	0.7946428571428571	0.8516746411483254	0.845
train	12	0.991869918699187	0.976	0.9838709677419355	0.984
eval	12	0.9245283018867925	0.875	0.8990825688073395	0.89
train	13	1.0	0.98	0.98989898989899	0.99
eval	13	0.9134615384615384	0.8482142857142857	0.8796296296296297	0.87
train	14	0.9842209072978304	0.998	0.9910625620655412	0.991
eval	14	0.8861788617886179	0.9732142857142857	0.9276595744680852	0.915
train	15	1.0	0.888	0.940677966101695	0.944
eval	15	0.9387755102040817	0.8214285714285714	0.8761904761904763	0.87
train	16	1.0	0.998	0.998998998998999	0.999
eval	16	0.9009009009009009	0.8928571428571429	0.8968609865470852	0.885
train	17	1.0	1.0	1.0	1.0
eval	17	0.9017857142857143	0.9017857142857143	0.9017857142857143	0.89
train	18	1.0	0.994	0.9969909729187563	0.997
eval	18	0.8956521739130435	0.9196428571428571	0.9074889867841409	0.895
train	19	0.9979959919839679	0.996	0.9969969969969971	0.997
eval	19	0.8717948717948718	0.9107142857142857	0.8908296943231441	0.875
train	20	0.9979296066252588	0.964	0.9806714140386572	0.981
eval	20	0.9191919191919192	0.8125	0.8625592417061612	0.855
train	21	0.9979633401221996	0.98	0.9889001009081735	0.989
eval	21	0.908256880733945	0.8839285714285714	0.8959276018099548	0.885
train	22	1.0	0.998	0.998998998998999	0.999
eval	22	0.8487394957983193	0.9017857142857143	0.8744588744588744	0.855
train	23	0.998	0.998	0.998	0.998
eval	23	0.8983050847457628	0.9464285714285714	0.9217391304347826	0.91
train	24	0.9939024390243902	0.978	0.9858870967741936	0.986
eval	24	0.860655737704918	0.9375	0.8974358974358975	0.88
train	25	0.9576923076923077	0.996	0.9764705882352941	0.976
eval	25	0.7956204379562044	0.9732142857142857	0.8755020080321285	0.845
train	26	0.9822834645669292	0.998	0.9900793650793651	0.99
eval	26	0.8571428571428571	0.9642857142857143	0.9075630252100839	0.89
train	27	0.8210180623973727	1.0	0.9017132551848512	0.891
eval	27	0.717948717948718	1.0	0.835820895522388	0.78
train	28	0.931098696461825	1.0	0.9643201542912246	0.963
eval	28	0.7913669064748201	0.9821428571428571	0.8764940239043824	0.845
train	29	0.945179584120983	1.0	0.9718172983479105	0.971
eval	29	0.8102189781021898	0.9910714285714286	0.891566265060241	0.865
