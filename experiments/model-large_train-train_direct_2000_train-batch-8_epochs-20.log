Run configurations: model=allenai/unifiedqa-v2-t5-large-1251000 train=./data/unifiedQA/train_direct_2000.json eval=./data/unifiedQA/test.json train_batch=8 eval_batch=16 epochs=20
Dataset	Epoch	Precision	Recall	F1	Accuracy
train	-1	0.7783251231527094	0.79	0.7841191066997518	0.7825
eval	-1	0.9411764705882353	0.8727272727272727	0.9056603773584905	0.9
train	0	0.9026465028355387	0.955	0.9280855199222545	0.926
eval	0	0.9272727272727272	0.9272727272727272	0.9272727272727272	0.92
train	1	0.9847405900305188	0.968	0.9762985375693394	0.9765
eval	1	0.926605504587156	0.9181818181818182	0.9223744292237444	0.915
train	2	0.9930417495029821	0.999	0.9960119641076769	0.996
eval	2	0.8974358974358975	0.9545454545454546	0.9251101321585904	0.915
train	3	0.9989327641408752	0.9369369369369369	0.9669421487603307	0.9635
eval	3	0.87	0.7909090909090909	0.8285714285714286	0.82
train	4	0.9107468123861566	1.0	0.9532888465204957	0.951
eval	4	0.8208955223880597	1.0	0.9016393442622952	0.88
train	5	0.9969450101832994	0.979	0.987891019172553	0.988
eval	5	0.9183673469387755	0.8181818181818182	0.8653846153846154	0.86
train	6	0.9930348258706467	0.998	0.9955112219451371	0.9955
eval	6	0.9122807017543859	0.9454545454545454	0.9285714285714285	0.92
train	7	1.0	0.984	0.9919354838709677	0.992
eval	7	0.9339622641509434	0.9	0.9166666666666666	0.91
train	8	0.9900695134061569	0.997	0.9935226706527155	0.9935
eval	8	0.896551724137931	0.9454545454545454	0.920353982300885	0.91
train	9	1.0	0.994	0.9969909729187563	0.997
eval	9	0.9130434782608695	0.9545454545454546	0.9333333333333332	0.925
train	10	0.9989949748743718	0.994	0.9964912280701754	0.9965
eval	10	0.9	0.9	0.9	0.89
train	11	0.9930139720558883	0.995	0.994005994005994	0.9935
eval	11	0.896551724137931	0.9454545454545454	0.920353982300885	0.91
train	12	0.998998998998999	0.998	0.9984992496248123	0.9985
eval	12	0.8782608695652174	0.9181818181818182	0.8977777777777778	0.885
train	13	0.996003996003996	0.997	0.9965017491254373	0.9965
eval	13	0.9130434782608695	0.9545454545454546	0.9333333333333332	0.925
train	14	0.9812992125984252	0.997	0.9890873015873016	0.989
eval	14	0.84251968503937	0.9727272727272728	0.9029535864978903	0.885
train	15	0.985207100591716	0.999	0.9920556107249257	0.9915
eval	15	0.896551724137931	0.9454545454545454	0.920353982300885	0.91
train	16	1.0	0.958	0.9785495403472931	0.979
eval	16	0.9456521739130435	0.7909090909090909	0.8613861386138613	0.86
train	17	0.9890981169474727	0.998	0.9935291189646591	0.9935
eval	17	0.8695652173913043	0.9090909090909091	0.888888888888889	0.875
train	18	1.0	0.9849699398797596	0.9924280666330136	0.99
eval	18	0.8818181818181818	0.8818181818181818	0.8818181818181818	0.87
train	19	0.9969879518072289	0.993	0.9949899799599199	0.995
eval	19	0.8807339449541285	0.8727272727272727	0.8767123287671234	0.865
