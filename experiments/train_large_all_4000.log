Run configurations: model=allenai/unifiedqa-v2-t5-large-1251000 train=./data/unifiedQA/train_all_4000.json eval=./data/unifiedQA/test.json train_batch=4 eval_batch=8 epochs=30
Dataset	Epoch	Precision	Recall	F1	Accuracy
train	-1	0.7357609710550888	0.7883941970985493	0.76116879980681	0.752
eval	-1	0.9411764705882353	0.8571428571428571	0.897196261682243	0.89
train	0	0.9494640122511485	0.93	0.9396312200050518	0.94
eval	0	0.9122807017543859	0.9285714285714286	0.9203539823008849	0.91
train	1	0.9653808110781404	0.976	0.9706613625062158	0.9705
eval	1	0.8727272727272727	0.8571428571428571	0.8648648648648648	0.85
train	2	0.972458688032048	0.971	0.971728796597448	0.97175
eval	2	0.8703703703703703	0.8392857142857143	0.8545454545454546	0.84
train	3	0.8860195903829029	0.995	0.9373528026377768	0.9335
eval	3	0.8270676691729323	0.9821428571428571	0.8979591836734694	0.875
train	4	0.9624505928853755	0.974	0.9681908548707753	0.968
eval	4	0.89	0.7946428571428571	0.839622641509434	0.83
train	5	0.9374407582938389	0.989	0.9625304136253042	0.9615
eval	5	0.7906976744186046	0.9107142857142857	0.846473029045643	0.815
train	6	0.9784061696658097	0.9515	0.964765525982256	0.96525
eval	6	0.8761061946902655	0.8839285714285714	0.88	0.865
train	7	0.8885393258426967	0.9885	0.9358579881656806	0.93225
eval	7	0.7133333333333334	0.9553571428571429	0.816793893129771	0.76
train	8	0.9468503937007874	0.962	0.9543650793650794	0.954
eval	8	0.7961165048543689	0.7321428571428571	0.7627906976744185	0.745
train	9	0.9123543123543123	0.9785	0.944270205066345	0.94225
eval	9	0.7022900763358778	0.8214285714285714	0.7572016460905349	0.705
train	10	0.8218243819266837	0.964	0.8872526461113668	0.8775
eval	10	0.635036496350365	0.7767857142857143	0.6987951807228916	0.625
train	11	0.7888667992047713	0.992	0.8788482834994462	0.86325
eval	11	0.6266666666666667	0.8392857142857143	0.7175572519083969	0.63
train	12	0.944770283479961	0.9665	0.9555116164112706	0.955
eval	12	0.6836734693877551	0.5982142857142857	0.6380952380952382	0.62
train	13	0.9537688442211055	0.949	0.9513784461152882	0.9515
eval	13	0.7525773195876289	0.6517857142857143	0.6985645933014354	0.685
train	14	0.9505283381364072	0.9895	0.9696227339539443	0.969
eval	14	0.7079646017699115	0.7142857142857143	0.7111111111111112	0.675
train	15	0.9595121951219512	0.9835	0.971358024691358	0.971
eval	15	0.6944444444444444	0.6696428571428571	0.6818181818181819	0.65
train	16	0.9969356486210419	0.976	0.9863567458312279	0.9865
eval	16	0.7375	0.5267857142857143	0.6145833333333335	0.63
train	17	0.9835411471321696	0.986	0.9847690387016229	0.98475
eval	17	0.75	0.6160714285714286	0.6764705882352942	0.67
train	18	0.9969727547931383	0.988	0.9924660974384732	0.9925
eval	18	0.7532467532467533	0.5178571428571429	0.6137566137566138	0.635
train	19	0.997	0.997	0.997	0.997
eval	19	0.746268656716418	0.44642857142857145	0.5586592178770949	0.605
train	20	0.998995983935743	0.995	0.9969939879759518	0.997
eval	20	0.7297297297297297	0.48214285714285715	0.5806451612903226	0.61
train	21	0.9964964964964965	0.9955	0.9959979989994997	0.996
eval	21	0.6941176470588235	0.5267857142857143	0.5989847715736041	0.605
train	22	0.9994997498749375	0.999	0.9992498124531133	0.99925
eval	22	0.6627906976744186	0.5089285714285714	0.5757575757575757	0.58
train	23	1.0	0.999	0.9994997498749374	0.9995
eval	23	0.6976744186046512	0.5357142857142857	0.6060606060606061	0.61
train	24	1.0	0.9995	0.9997499374843711	0.99975
eval	24	0.6986301369863014	0.45535714285714285	0.5513513513513514	0.585
train	25	1.0	0.9995	0.9997499374843711	0.99975
eval	25	0.7073170731707317	0.5178571428571429	0.5979381443298969	0.61
train	26	1.0	1.0	1.0	1.0
eval	26	0.7297297297297297	0.48214285714285715	0.5806451612903226	0.61
train	27	1.0	1.0	1.0	1.0
eval	27	0.7105263157894737	0.48214285714285715	0.5744680851063829	0.6
train	28	1.0	1.0	1.0	1.0
eval	28	0.7105263157894737	0.48214285714285715	0.5744680851063829	0.6
train	29	1.0	1.0	1.0	1.0
eval	29	0.7105263157894737	0.48214285714285715	0.5744680851063829	0.6
