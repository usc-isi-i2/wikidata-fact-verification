Run configurations: model=allenai/unifiedqa-v2-t5-base-1251000 train=./data/unifiedQA/train_direct_2000.json eval=./data/unifiedQA/test.json train_batch=4 eval_batch=16 epochs=20
Dataset	Epoch	Precision	Recall	F1	Accuracy
train	-1	0.6441808747220164	0.869	0.7398893146019583	0.6945
eval	-1	0.803030303030303	0.9636363636363636	0.8760330578512396	0.85
train	0	0.9411187438665358	0.959	0.9499752352649826	0.9495
eval	0	0.926605504587156	0.9181818181818182	0.9223744292237444	0.915
train	1	0.9880358923230309	0.991	0.9895157264103844	0.9895
eval	1	0.9339622641509434	0.9	0.9166666666666666	0.91
train	2	0.9949647532729103	0.988	0.9914701455092825	0.9915
eval	2	0.9065420560747663	0.8818181818181818	0.8940092165898617	0.885
train	3	0.9970089730807578	1.0	0.9985022466300548	0.9985
eval	3	0.8632478632478633	0.9181818181818182	0.8898678414096917	0.875
train	4	0.996003996003996	0.997	0.9965017491254373	0.9965
eval	4	0.9351851851851852	0.9181818181818182	0.9266055045871558	0.92
train	5	1.0	0.994	0.9969909729187563	0.997
eval	5	0.9230769230769231	0.8727272727272727	0.897196261682243	0.89
train	6	0.9871287128712871	0.997	0.992039800995025	0.992
eval	6	0.8403361344537815	0.9090909090909091	0.8733624454148471	0.855
train	7	0.9967707212055974	0.926	0.9600829445308451	0.9615
eval	7	0.9065420560747663	0.8818181818181818	0.8940092165898617	0.885
train	8	0.9949290060851927	0.981	0.987915407854985	0.988
eval	8	0.8738738738738738	0.8818181818181818	0.8778280542986425	0.865
train	9	0.9215143120960295	0.998	0.958233317330773	0.9565
eval	9	0.8014705882352942	0.990909090909091	0.8861788617886179	0.86
train	10	0.9969879518072289	0.993	0.9949899799599199	0.995
eval	10	0.8909090909090909	0.8909090909090909	0.8909090909090909	0.88
train	11	0.9624277456647399	0.999	0.9803729146221786	0.98
eval	11	0.7769784172661871	0.9818181818181818	0.8674698795180722	0.835
train	12	0.9689922480620154	1.0	0.9842519685039369	0.984
eval	12	0.7956204379562044	0.990909090909091	0.8825910931174089	0.855
train	13	0.9979859013091642	0.991	0.9944806823883593	0.9945
eval	13	0.8548387096774194	0.9636363636363636	0.905982905982906	0.89
train	14	0.9960079840319361	0.998	0.997002997002997	0.997
eval	14	0.8188976377952756	0.9454545454545454	0.8776371308016877	0.855
train	15	0.9909638554216867	0.987	0.9889779559118237	0.989
eval	15	0.8429752066115702	0.9272727272727272	0.8831168831168832	0.865
train	16	0.9927310488058152	0.956	0.9740193581253184	0.9745
eval	16	0.8085106382978723	0.6909090909090909	0.7450980392156863	0.74
train	17	0.997	0.997	0.997	0.997
eval	17	0.7286821705426356	0.8545454545454545	0.7866108786610878	0.745
train	18	0.9680232558139535	0.999	0.9832677165354331	0.983
eval	18	0.6733333333333333	0.9181818181818182	0.7769230769230769	0.71
train	19	0.9652173913043478	0.999	0.9818181818181818	0.9815
eval	19	0.6870748299319728	0.9181818181818182	0.7859922178988328	0.725
