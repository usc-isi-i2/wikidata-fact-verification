Run configurations: model=allenai/unifiedqa-v2-t5-base-1251000 train=./data/unifiedQA/train_direct_5208.json eval=./data/unifiedQA/test.json train_batch=16 eval_batch=16 epochs=20
Dataset	Epoch	Precision	Recall	F1	Accuracy
train	-1	0.6298755186721992	0.8744239631336406	0.7322720694645442	0.6801075268817204
eval	-1	0.803030303030303	0.9636363636363636	0.8760330578512396	0.85
train	0	0.9783783783783784	0.8341013824884793	0.900497512437811	0.9078341013824884
eval	0	0.9069767441860465	0.7090909090909091	0.7959183673469388	0.8
train	1	0.9972505891594659	0.9750384024577573	0.9860194174757281	0.9861751152073732
eval	1	0.9183673469387755	0.8181818181818182	0.8653846153846154	0.86
train	2	0.9946401225114855	0.9976958525345622	0.9961656441717792	0.9961597542242704
eval	2	0.9304347826086956	0.9727272727272728	0.9511111111111111	0.945
train	3	0.9984609465178915	0.9965437788018433	0.9975014414760716	0.9975038402457758
eval	3	0.918918918918919	0.9272727272727272	0.9230769230769231	0.915
train	4	0.9969088098918083	0.9907834101382489	0.9938366718027735	0.9938556067588326
eval	4	0.9252336448598131	0.9	0.9124423963133641	0.905
train	5	0.9942462600690449	0.9953917050691244	0.9948186528497409	0.994815668202765
eval	5	0.911504424778761	0.9363636363636364	0.9237668161434978	0.915
train	6	0.9455139847439157	0.9996159754224271	0.9718125816688444	0.9710061443932412
eval	6	0.8384615384615385	0.990909090909091	0.9083333333333334	0.89
train	7	0.9980813507290868	0.9988479262672811	0.998464491362764	0.9984639016897081
eval	7	0.8852459016393442	0.9818181818181818	0.9310344827586207	0.92
train	8	0.9800301431801055	0.9988479262672811	0.9893495625713199	0.989247311827957
eval	8	0.8211382113821138	0.9181818181818182	0.8669527896995709	0.845
train	9	0.9942218798151001	0.9911674347158218	0.9926923076923078	0.9927035330261137
eval	9	0.8990825688073395	0.8909090909090909	0.8949771689497716	0.885
train	10	0.9965451055662188	0.9969278033794163	0.9967364177385295	0.9967357910906298
eval	10	0.8790322580645161	0.990909090909091	0.9316239316239316	0.92
train	11	0.9992119779353822	0.9738863287250384	0.9863866199922209	0.9865591397849462
eval	11	0.9108910891089109	0.8363636363636363	0.8720379146919431	0.865
train	12	0.9980761831473643	0.9961597542242704	0.9971170478570055	0.9971198156682027
eval	12	0.9285714285714286	0.9454545454545454	0.9369369369369368	0.93
train	13	0.996547756041427	0.9976958525345622	0.9971214738054116	0.9971198156682027
eval	13	0.9122807017543859	0.9454545454545454	0.9285714285714285	0.92
train	14	0.9919877909194964	0.9984639016897081	0.9952153110047848	0.9951996927803379
eval	14	0.8548387096774194	0.9636363636363636	0.905982905982906	0.89
train	15	0.9988479262672811	0.9988479262672811	0.9988479262672811	0.9988479262672811
eval	15	0.8455284552845529	0.9454545454545454	0.8927038626609443	0.875
train	16	0.9950210647261586	0.9976958525345622	0.9963566634707574	0.9963517665130568
eval	16	0.8870967741935484	1.0	0.9401709401709402	0.93
train	17	0.998842145889618	0.9938556067588326	0.9963426371511069	0.9963517665130568
eval	17	0.9099099099099099	0.9181818181818182	0.914027149321267	0.905
train	18	0.9934815950920245	0.9950076804915514	0.9942440521872601	0.993663594470046
eval	18	0.824	0.9363636363636364	0.876595744680851	0.855
train	19	0.9814674735249622	0.9965437788018433	0.9889481707317073	0.988863287250384
eval	19	0.864	0.9818181818181818	0.9191489361702128	0.905
