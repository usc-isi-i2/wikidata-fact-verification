{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "train_data = json.load(open('../data/unlabelled/train_fact_verification_support_data.json'))\n",
    "\n",
    "test_data_common = json.load(open('../data/unlabelled/gt_fact_verification_support_data.json'))\n",
    "test_data_only_dbp = json.load(open('../data/unlabelled/gt_only_dbp_support_data.json'))\n",
    "test_data = test_data_common + test_data_only_dbp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"huggingface-course/bert-finetuned-ner\"\n",
    "token_classifier = pipeline(\"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total persons in test facts: 396\n"
     ]
    }
   ],
   "source": [
    "test_data_persons = set()\n",
    "for data in test_data:\n",
    "    for person in data['pair']:\n",
    "        test_data_persons.add(person)\n",
    "\n",
    "print(f'Total persons in test facts: {len(test_data_persons)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:51<00:00,  6.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "from collections import defaultdict\n",
    "\n",
    "train_facts = []\n",
    "train_facts_direct = []\n",
    "train_facts_only_negative_others = []\n",
    "train_facts_only_positive_others = []\n",
    "\n",
    "for data in tqdm(train_data):\n",
    "    person_one, person_two = data['pair']\n",
    "    if any((person in test_data_persons) for person in data['pair']):\n",
    "        continue\n",
    "\n",
    "    for support in data['supports']:\n",
    "        other_persons = []\n",
    "        pair_names = defaultdict(list)\n",
    "\n",
    "        evidence = support['content'].replace('\\n', ' ')\n",
    "        entities = token_classifier(evidence)\n",
    "\n",
    "        for entity in entities:\n",
    "            if entity['entity_group'] != 'PER':\n",
    "                continue\n",
    "\n",
    "            person_name = entity['word']\n",
    "            if person_one in person_name or person_name in person_one:\n",
    "                pair_names[person_one].append(person_name)\n",
    "                continue\n",
    "\n",
    "            if person_two in person_name or person_name in person_two:\n",
    "                pair_names[person_two].append(person_name)\n",
    "                continue\n",
    "\n",
    "            other_persons.append(person_name)\n",
    "\n",
    "        person_one_names, person_two_names = pair_names[person_one], pair_names[person_two]\n",
    "        shuffle(person_one_names), shuffle(person_two_names), shuffle(other_persons)\n",
    "\n",
    "        if all(v for v in pair_names.values()):\n",
    "            train_facts.append({'input': f'Is {person_one} married with {person_two}?\\n{evidence}', 'output': 'yes'})\n",
    "            train_facts.append({'input': f'Is {person_two} married with {person_one}?\\n{evidence}', 'output': 'yes'})\n",
    "\n",
    "            train_facts_direct.append({'input': f'Is {person_one} married with {person_two}?\\n{evidence}', 'output': 'yes'})\n",
    "            train_facts_direct.append({'input': f'Is {person_two} married with {person_one}?\\n{evidence}', 'output': 'yes'})\n",
    "\n",
    "            if person_one_names[0] != person_one or person_two_names[0] != person_two:\n",
    "                train_facts.append({'input': f'Is {person_one_names[0]} married with {person_two_names[0]}?\\n{evidence}', 'output': 'yes'})\n",
    "                train_facts.append({'input': f'Is {person_two_names[0]} married with {person_one_names[0]}?\\n{evidence}', 'output': 'yes'})\n",
    "\n",
    "                train_facts_only_positive_others.append({'input': f'Is {person_one_names[0]} married with {person_two_names[0]}?\\n{evidence}', 'output': 'yes'})\n",
    "                train_facts_only_positive_others.append({'input': f'Is {person_two_names[0]} married with {person_one_names[0]}?\\n{evidence}', 'output': 'yes'})\n",
    "\n",
    "        else:\n",
    "            train_facts.append({'input': f'Is {person_one} married with {person_two}?\\n{evidence}', 'output': 'no'})\n",
    "            train_facts.append({'input': f'Is {person_two} married with {person_one}?\\n{evidence}', 'output': 'no'})\n",
    "\n",
    "            train_facts_direct.append({'input': f'Is {person_one} married with {person_two}?\\n{evidence}', 'output': 'no'})\n",
    "            train_facts_direct.append({'input': f'Is {person_two} married with {person_one}?\\n{evidence}', 'output': 'no'})\n",
    "\n",
    "        if len(other_persons) >= 2:\n",
    "            train_facts.append({'input': f'Is {other_persons[0]} married with {other_persons[1]}?\\n{evidence}', 'output': 'no'})\n",
    "            train_facts.append({'input': f'Is {other_persons[1]} married with {other_persons[0]}?\\n{evidence}', 'output': 'no'})\n",
    "\n",
    "            train_facts_only_negative_others.append({'input': f'Is {other_persons[0]} married with {other_persons[1]}?\\n{evidence}', 'output': 'no'})\n",
    "            train_facts_only_negative_others.append({'input': f'Is {other_persons[1]} married with {other_persons[0]}?\\n{evidence}', 'output': 'no'})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "(16524, 7558, 8966, 0)"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(train_facts)\n",
    "pos_count = len([fact for fact in train_facts if fact['output'] == 'yes'])\n",
    "neg_count = len([fact for fact in train_facts if fact['output'] == 'no'])\n",
    "json.dump(train_facts, open('../data/unifiedQA/train.json', 'w'))\n",
    "total, pos_count, neg_count, total - (pos_count + neg_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "(6864, 4260, 2604, 0)"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(train_facts_direct)\n",
    "pos_count = len([fact for fact in train_facts_direct if fact['output'] == 'yes'])\n",
    "neg_count = len([fact for fact in train_facts_direct if fact['output'] == 'no'])\n",
    "json.dump(train_facts_direct, open('../data/unifiedQA/train_direct.json', 'w'))\n",
    "total, pos_count, neg_count, total - (pos_count + neg_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "(10162, 7558, 2604, 0)"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_facts_only_positive_others +=  train_facts_direct\n",
    "total = len(train_facts_only_positive_others)\n",
    "pos_count = len([fact for fact in train_facts_only_positive_others if fact['output'] == 'yes'])\n",
    "neg_count = len([fact for fact in train_facts_only_positive_others if fact['output'] == 'no'])\n",
    "json.dump(train_facts_only_positive_others, open('../data/unifiedQA/train_extra_pos.json', 'w'))\n",
    "total, pos_count, neg_count, total - (pos_count + neg_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "(13226, 4260, 8966, 0)"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_facts_only_negative_others += train_facts_direct\n",
    "total = len(train_facts_only_negative_others)\n",
    "pos_count = len([fact for fact in train_facts_only_negative_others if fact['output'] == 'yes'])\n",
    "neg_count = len([fact for fact in train_facts_only_negative_others if fact['output'] == 'no'])\n",
    "json.dump(train_facts_only_negative_others, open('../data/unifiedQA/train_extra_neg.json', 'w'))\n",
    "total, pos_count, neg_count, total - (pos_count + neg_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 629, 371, 0)"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle(train_facts_direct)\n",
    "train_direct_small_facts = train_facts_direct[:1000]\n",
    "total = len(train_direct_small_facts)\n",
    "pos_count = len([fact for fact in train_direct_small_facts if fact['output'] == 'yes'])\n",
    "neg_count = len([fact for fact in train_direct_small_facts if fact['output'] == 'no'])\n",
    "json.dump(train_direct_small_facts, open('../data/unifiedQA/train_direct_small.json', 'w'))\n",
    "total, pos_count, neg_count, total - (pos_count + neg_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 470, 530, 0)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle(train_facts)\n",
    "train_small_facts = train_facts[:1000]\n",
    "total = len(train_small_facts)\n",
    "pos_count = len([fact for fact in train_small_facts if fact['output'] == 'yes'])\n",
    "neg_count = len([fact for fact in train_small_facts if fact['output'] == 'no'])\n",
    "json.dump(train_small_facts, open('../data/unifiedQA/train_small.json', 'w'))\n",
    "total, pos_count, neg_count, total - (pos_count + neg_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}